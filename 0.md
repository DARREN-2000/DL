# Pattern Generation in Deep Learning: Exercise 0 Comprehensive Guide

## 1. Overview and Purpose

This exercise introduces fundamental concepts in pattern generation for deep learning applications. The project consists of three Python files:

- **pattern.py**: Defines pattern classes and rendering logic
- **generator.py**: Creates datasets of patterns for training and testing
- **main.py**: Demonstrates usage and visualization of patterns

**Core Learning Objectives:**
- Understand how to generate synthetic data for neural networks
- Implement object-oriented programming in machine learning projects
- Create visualization systems for data inspection
- Design reusable and extensible pattern generation components

## 2. Pattern Classes (pattern.py)

### 2.1 Base Class

```python
class Pattern:
    """Base class for all patterns"""
    def __init__(self, resolution):
        self.resolution = resolution
    
    def draw(self):
        """Return a pattern as numpy array with shape (resolution, resolution)"""
        raise NotImplementedError
```

**Key Points:**
- Uses **abstract base class** pattern with `resolution` parameter
- `draw()` method must be implemented by child classes
- Returns a 2D numpy array representing the pattern

### 2.2 Derived Pattern Classes

#### CheckerboardPattern
```python
class CheckerboardPattern(Pattern):
    def __init__(self, resolution, tiles=4):
        super().__init__(resolution)
        self.tiles = tiles
    
    def draw(self):
        tile_size = self.resolution // self.tiles
        pattern = np.zeros((self.resolution, self.resolution))
        
        for i in range(self.tiles):
            for j in range(self.tiles):
                if (i + j) % 2 == 0:
                    row_start, row_end = i * tile_size, (i + 1) * tile_size
                    col_start, col_end = j * tile_size, (j + 1) * tile_size
                    pattern[row_start:row_end, col_start:col_end] = 1
        
        return pattern
```

**Algorithm Breakdown:**
- Divides image into `tiles × tiles` grid
- Uses modulo operation `(i + j) % 2` to create alternating pattern
- Fills square regions with 1s (white) or 0s (black)

#### CirclePattern
```python
class CirclePattern(Pattern):
    def __init__(self, resolution, radius_fraction=0.4):
        super().__init__(resolution)
        self.radius = radius_fraction * resolution / 2
    
    def draw(self):
        pattern = np.zeros((self.resolution, self.resolution))
        center = self.resolution / 2
        
        for i in range(self.resolution):
            for j in range(self.resolution):
                if (i - center)**2 + (j - center)**2 <= self.radius**2:
                    pattern[i, j] = 1
        
        return pattern
```

**Mathematical Principle:**
- Uses the circle equation: $(x - h)^2 + (y - k)^2 = r^2$
- `radius_fraction` controls circle size relative to image
- Points inside circle = 1, outside = 0

#### GradientPattern
```python
class GradientPattern(Pattern):
    def __init__(self, resolution, direction='horizontal'):
        super().__init__(resolution)
        self.direction = direction
    
    def draw(self):
        if self.direction == 'horizontal':
            return np.tile(np.linspace(0, 1, self.resolution), (self.resolution, 1))
        else:  # 'vertical'
            return np.tile(np.linspace(0, 1, self.resolution).reshape(-1, 1), (1, self.resolution))
```

**Implementation Notes:**
- Uses `np.linspace(0, 1, resolution)` to create gradient values
- `np.tile` replicates the gradient across rows/columns
- Direction parameter controls orientation (horizontal/vertical)

#### RandomPattern
```python
class RandomPattern(Pattern):
    def __init__(self, resolution, seed=None):
        super().__init__(resolution)
        self.seed = seed
    
    def draw(self):
        if self.seed is not None:
            np.random.seed(self.seed)
        return np.random.random((self.resolution, self.resolution))
```

**Important Concepts:**
- Optional `seed` parameter for reproducibility
- Returns uniform random values between 0 and 1
- New random values each time `draw()` is called (unless seeded)

## 3. Pattern Generator (generator.py)

### 3.1 PatternGenerator Class

```python
class PatternGenerator:
    def __init__(self, resolution=64):
        self.resolution = resolution
        self.patterns = {
            'checkerboard': CheckerboardPattern,
            'circle': CirclePattern,
            'gradient_h': lambda res: GradientPattern(res, 'horizontal'),
            'gradient_v': lambda res: GradientPattern(res, 'vertical'),
            'random': RandomPattern
        }
```

**Design Pattern:**
- Implements **Factory Pattern** to create different pattern types
- Uses dictionary with lambda functions to configure patterns
- Default resolution = 64×64 pixels

### 3.2 Dataset Generation Methods

#### Single Pattern Type
```python
def generate(self, pattern_type, count=1, **kwargs):
    if pattern_type not in self.patterns:
        raise ValueError(f"Pattern type '{pattern_type}' not recognized")
    
    pattern_class = self.patterns[pattern_type]
    dataset = np.zeros((count, self.resolution, self.resolution))
    
    for i in range(count):
        pattern = pattern_class(self.resolution, **kwargs)
        dataset[i] = pattern.draw()
        
    return dataset
```

**Key Features:**
- Creates `count` instances of a specific pattern
- Accepts arbitrary keyword arguments (`**kwargs`) for pattern configuration
- Returns a 3D tensor with shape (count, resolution, resolution)

#### Mixed Dataset
```python
def generate_mixed_dataset(self, pattern_counts, **kwargs):
    total_count = sum(pattern_counts.values())
    data = np.zeros((total_count, self.resolution, self.resolution))
    labels = np.zeros(total_count, dtype=int)
    
    idx = 0
    for i, (pattern_type, count) in enumerate(pattern_counts.items()):
        if count > 0:
            patterns = self.generate(pattern_type, count, **kwargs.get(pattern_type, {}))
            data[idx:idx+count] = patterns
            labels[idx:idx+count] = i
            idx += count
            
    # Shuffle the dataset
    shuffle_idx = np.random.permutation(total_count)
    return data[shuffle_idx], labels[shuffle_idx]
```

**Machine Learning Aspects:**
- Creates labeled dataset with multiple pattern classes
- Assigns integer class labels automatically (0, 1, 2, ...)
- Randomly shuffles data and labels using permutation
- Returns (data, labels) tuple ready for ML training

## 4. Visualization and Demo (main.py)

### 4.1 Display Function

```python
def display_patterns(patterns, titles=None, cmap='viridis'):
    n = patterns.shape[0]
    cols = min(n, 4)
    rows = (n + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))
    if rows == 1 and cols == 1:
        axes = np.array([axes])
    axes = axes.flatten()
    
    for i in range(n):
        axes[i].imshow(patterns[i], cmap=cmap)
        axes[i].axis('off')
        if titles is not None and i < len(titles):
            axes[i].set_title(titles[i])
    
    # Hide unused subplots
    for i in range(n, len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.show()
```

**Visualization Techniques:**
- Creates grid layout with maximum 4 columns
- Uses `imshow()` with colormap for displaying 2D arrays
- Handles special case for single image
- Supports optional titles for each pattern

### 4.2 Main Demonstration

```python
def main():
    # Create a pattern generator
    generator = PatternGenerator(resolution=64)
    
    # Generate different types of patterns
    patterns = []
    titles = []
    
    # Checkerboard patterns with different numbers of tiles
    for tiles in [2, 4, 8]:
        patterns.append(generator.generate('checkerboard', 1, tiles=tiles)[0])
        titles.append(f'Checkerboard ({tiles}x{tiles})')
    
    # Circle patterns with different radii
    for radius in [0.2, 0.4, 0.6]:
        patterns.append(generator.generate('circle', 1, radius_fraction=radius)[0])
        titles.append(f'Circle (r={radius})')
    
    # Gradient patterns
    patterns.append(generator.generate('gradient_h', 1)[0])
    titles.append('Horizontal Gradient')
    patterns.append(generator.generate('gradient_v', 1)[0])
    titles.append('Vertical Gradient')
    
    # Random patterns
    patterns.append(generator.generate('random', 1)[0])
    titles.append('Random')
    
    # Display all patterns
    display_patterns(np.array(patterns), titles)
    
    # Generate and display a mixed dataset
    print("Generating a mixed dataset...")
    data, labels = generator.generate_mixed_dataset({
        'checkerboard': 2,
        'circle': 2,
        'gradient_h': 2,
        'random': 2
    })
    
    # Display a subset of the mixed dataset
    sample_idx = np.random.choice(len(data), size=8, replace=False)
    display_patterns(data[sample_idx], 
                    [f"Class {labels[i]}" for i in sample_idx])
```

**Demonstration Flow:**
1. Creates patterns with varying parameters 
2. Shows pattern variation within each class
3. Generates balanced mixed dataset (2 samples per class)
4. Randomly selects 8 samples to display
5. Shows class labels for each sample

## 5. Key Concepts for MCQ Preparation

### 5.1 Numpy Operations

- **np.zeros((rows, cols))**: Creates 2D array filled with zeros
- **np.linspace(start, stop, num)**: Creates evenly spaced values
- **np.tile(array, reps)**: Repeats array to create larger array
- **np.random.random(shape)**: Generates random values between 0-1
- **np.random.permutation(n)**: Returns random permutation of integers
- **np.random.choice(array, size)**: Randomly samples elements from array

### 5.2 OOP Principles

- **Inheritance**: Pattern classes inherit from base Pattern class
- **Polymorphism**: draw() method works differently for each pattern
- **Encapsulation**: Implementation details hidden within classes
- **Abstraction**: Base class defines interface for all patterns

### 5.3 Pattern Generation Algorithms

- **Checkerboard**: Uses modulo arithmetic and grid division
- **Circle**: Based on Euclidean distance from center point
- **Gradient**: Uses linear interpolation and repetition
- **Random**: Based on uniform distribution random sampling

### 5.4 Dataset Characteristics

- **Resolution**: All patterns have same dimensions (resolution × resolution)
- **Value Range**: All pattern values are normalized to [0,1] range
- **Classes**: Each pattern type represents a distinct class
- **Labeling**: Integer labels assigned to each pattern type

### 5.5 Function Parameter Patterns

- **Default Parameters**: Most functions have sensible defaults
- **Keyword Arguments**: Flexible parameter passing with `**kwargs`
- **Variable Arguments**: Support for arbitrary parameters
- **Method Chaining**: Functions designed to be composed sequentially

## 6. Potential MCQ Topics

1. **Pattern Mathematics**
   - How is a circle determined mathematically in the CirclePattern class?
   - What does the modulo operation accomplish in the CheckerboardPattern?

2. **Data Representation**
   - What is the shape of the output from generator.generate('random', 5)?
   - What is the valid range of values in the pattern arrays?

3. **NumPy Functions**
   - What does np.tile() do in the GradientPattern class?
   - Why is reshape(-1, 1) used in vertical gradient generation?

4. **Dataset Manipulation**
   - How are labels assigned in the generate_mixed_dataset method?
   - What is the purpose of np.random.permutation in the dataset generation?

5. **OOP Concepts**
   - Why is draw() declared in the base Pattern class?
   - What design pattern is used in the PatternGenerator class?

6. **Visualization**
   - What does the 'cmap' parameter control in display_patterns()?
   - How is the grid layout determined in the display function?

## 7. Summary

This exercise provides a foundation for:
- Creating synthetic data for deep learning experiments
- Implementing reusable pattern generation classes
- Working with numpy arrays for image representation
- Applying object-oriented design to ML applications
- Building visualization tools for dataset inspection

Understanding these concepts will be crucial for future exercises that involve more complex deep learning architectures and data processing pipelines.